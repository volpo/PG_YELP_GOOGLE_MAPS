{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyOcEAYZ1dRzFBN9v6bYTME7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Data pipeline tool Mage ai"],"metadata":{"id":"x6b4wPqYZZcj"}},{"cell_type":"markdown","source":["**Cassandra to MySQL**\n","\n","**DataLake to DataWarehouse**"],"metadata":{"id":"KvtlMMZMaSEm"}},{"cell_type":"markdown","source":["Durante la implementacion y el uso de esta herramienta nos enfrentamos a varios desafíos, especialmente en el manejo de grandes volúmenes de datos en relación con los recursos disponibles en nuestro servidor donde se encuentra Mage. Para abordar estos problemas, se decidió no procesar todos los datos al mismo tiempo y se buscaron formas de particionarlos por regiones e índices. Se implementó un enfoque automatizado para procesar pequeñas cantidades de datos y cargarlos progresivamente en MySQL.\n","\n","Mas adelante se muestra parte del codigo final desplegado en mage, donde a partir de variables globales que lleva un conteo de los datos y la particion mas optima para cada caso, con lo que podemos ir cargando y procesando sin ningun problema asi como llevar registro de la cantidad de datos cargados, pensado tambien ya que se tiene una carga incremental a traves de las API's"],"metadata":{"id":"zzyNYcBZZvle"}},{"cell_type":"markdown","source":["**Desafíos encontrados**\n","\n","*Limitaciones de recursos del servidor: Nuestro servidor tenía recursos limitados para procesar grandes cantidades de datos de manera eficiente.\n","\n","*Procesamiento simultáneo de datos: La carga y el procesamiento de todos los datos al mismo tiempo causaban problemas de rendimiento y agotamiento de recursos.\n","\n","**Soluciones implementadas**\n","\n","*Particionamiento de datos por regiones e índices: En lugar de procesar todos los datos a la vez, se adoptó un enfoque de particionamiento. Se dividieron los datos en regiones y se aplicaron índices para facilitar la carga incremental y el procesamiento eficiente.\n","\n","*Carga y procesamiento progresivo: En lugar de cargar todos los datos de una vez, se implementó un mecanismo para cargar y procesar pequeñas cantidades de datos de manera automática y progresiva. Esto ayudó a evitar problemas de rendimiento y a aprovechar al máximo los recursos disponibles.\n","\n","*Uso de variables globales para el seguimiento y optimización: Se introdujeron variables globales en el código final para llevar un conteo de los datos cargados y determinar la partición óptima en función de la cantidad de datos y los recursos disponibles. Esto permitió un control más eficiente del proceso de carga y procesamiento de datos."],"metadata":{"id":"B5LCGjfbdLpA"}},{"cell_type":"markdown","source":["## stores_google"],"metadata":{"id":"-t1vx07_gY-4"}},{"cell_type":"code","source":["if 'data_loader' not in globals():\n","    from mage_ai.data_preparation.decorators import data_loader\n","if 'test' not in globals():\n","    from mage_ai.data_preparation.decorators import test\n","\n","from cassandra.cluster import Cluster\n","from cassandra.query import SimpleStatement, dict_factory\n","\n","import pandas as pd\n","\n","cluster = Cluster(['186.87.6.161'], port='9042', protocol_version = 5) #IP del servidor y el puerto estandar de cassandra 9042\n","session = cluster.connect('henry')\n","session.row_factory = dict_factory\n","\n","from mage_ai.data_preparation.variable_manager import set_global_variable\n","\n","@data_loader\n","def load_data(*args, **kwargs):\n","    \"\"\"\n","    Template code for loading data from any source.\n","\n","    Returns:\n","        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n","    \"\"\"\n","    categories_searched = ['Restaurant',\n","                        'restaurant',\n","                        'Bar',\n","                        'bar',\n","                        'Deli',\n","                        'Grocery',\n","                        'Coffee',\n","                        'Bakery',\n","                        'Sandwich']\n","\n","    dictionary = {'gmap_id':[],\n","                'name': [],\n","                'address': [],\n","                'latitude': [],\n","                'longitude': [],\n","                'category':[],\n","                'misc':[]}\n","\n","\n","\n","    for category_searched in categories_searched:\n","    # Construct the query\n","        query = f\"\"\"SELECT gmap_id, name, address, latitude, longitude, category, misc\n","                    FROM stores\n","                    WHERE category CONTAINS '{category_searched}'\n","                    \"\"\"\n","        statement = SimpleStatement(query, fetch_size=500)\n","        answer = session.execute(statement, timeout=None)\n","\n","        for row in answer:\n","            dictionary['gmap_id'].append(row['gmap_id'])\n","            dictionary['name'].append(row['name'])\n","            dictionary['address'].append(row['address'])\n","            dictionary['latitude'].append(row['latitude'])\n","            dictionary['longitude'].append(row['longitude'])\n","            # Convert the SortedSet to a comma-separated string\n","            category_str = ', '.join(row['category'])\n","            dictionary['category'].append(category_str)\n","            dictionary['misc'].append(row['misc'])\n","\n","\n","    stores = pd.DataFrame(dictionary)\n","\n","    return stores\n","\n","\n","@test\n","def test_output(output, *args) -> None:\n","    \"\"\"\n","    Template code for testing the output of the block.\n","    \"\"\"\n","    assert output is not None, 'The output is undefined'\n"],"metadata":{"id":"oTf3cKNzgZS5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Filtrado por estado\n","if 'transformer' not in globals():\n","    from mage_ai.data_preparation.decorators import transformer\n","if 'test' not in globals():\n","    from mage_ai.data_preparation.decorators import test\n","\n","import pandas as pd\n","\n","from geopy.geocoders import Nominatim\n","\n","from mage_ai.data_preparation.variable_manager import set_global_variable\n","\n","@transformer\n","def transform(stores, *args, **kwargs):\n","    \"\"\"\n","    Template code for a transformer block.\n","\n","    Add more parameters to this function if this block has multiple parent blocks.\n","    There should be one parameter for each output variable from each parent block.\n","\n","    Args:\n","        data: The output from the upstream parent block\n","        args: The output from any additional upstream blocks (if applicable)\n","\n","    Returns:\n","        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n","    \"\"\"\n","    # Acceder a las variables globales de carga\n","    indice_inicio = kwargs['indice_inicio']\n","    particion = kwargs['particion'] #100\n","\n","    indice_fin = indice_inicio + particion\n","\n","    #Particionar\n","    stores = stores[indice_inicio:indice_fin]\n","\n","\n","    # Instanciar la herramienta Nominatim\n","    geolocator = Nominatim(user_agent=\"GetLoc\")\n","\n","    # Definir los estados deseados\n","    estados_deseados = ['Florida', 'New York', 'California', 'Nevada', 'Texas']\n","\n","    # Filtrar los datos por estado\n","    df_filtrado = pd.DataFrame(columns=stores.columns)\n","\n","    for index, row in stores.iterrows():\n","        latitude = row['latitude']\n","        longitude = row['longitude']\n","        if pd.notnull(latitude) and pd.notnull(longitude):\n","            location = geolocator.reverse(f\"{latitude}, {longitude}\")\n","            if location is not None and 'address' in location.raw and 'state' in location.raw['address']:\n","                estado = location.raw['address']['state']\n","                if estado in estados_deseados:\n","                    row['state'] = estado\n","                    df_filtrado = df_filtrado.append(row)\n","\n","    stores_f = df_filtrado\n","\n","    indice_fin = min(indice_fin, indice_inicio + len(stores))\n","\n","    set_global_variable('stores_google', 'indice_inicio', indice_fin)\n","\n","    return stores_f\n","\n","\n","@test\n","def test_output(output, *args) -> None:\n","    \"\"\"\n","    Template code for testing the output of the block.\n","    \"\"\"\n","    assert output is not None, 'The output is undefined'\n"],"metadata":{"id":"qoHqdA9LgZQv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Tabla_locales\n","if 'custom' not in globals():\n","    from mage_ai.data_preparation.decorators import custom\n","if 'test' not in globals():\n","    from mage_ai.data_preparation.decorators import test\n","\n","from cassandra.cluster import Cluster\n","from cassandra.query import SimpleStatement, dict_factory\n","\n","cluster = Cluster(['186.87.6.161'], port='9042', protocol_version = 5) #IP del servidor y el puerto estandar de cassandra 9042\n","session = cluster.connect('henry')\n","session.row_factory = dict_factory\n","\n","import pandas as pd\n","\n","import mysql.connector\n","\n","mydb = mysql.connector.connect(\n","  host=\"162.241.60.182\",\n","  user=\"leudadoc_henry\",\n","  password=\"tenboj-dEckow-nokka8\",\n","  database=\"leudadoc_Henry\"\n",")\n","\n","cursor = mydb.cursor()\n","cursor.execute(\"USE leudadoc_Henry;\")\n","\n","@custom\n","def transform_custom(stores_f, *args, **kwargs):\n","    \"\"\"\n","    Args:\n","        data: The output from the upstream parent block (if applicable)\n","        args: The output from any additional upstream blocks\n","\n","    Returns:\n","        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n","    \"\"\"\n","    stores = stores_f\n","\n","    def check_delivery(x):\n","        service_options = x.get(\"misc\")\n","\n","        if service_options and \"Delivery\" in service_options:\n","            return \"Y\"\n","        else:\n","            return \"N\"\n","\n","    stores['delivery'] = stores.apply(check_delivery, axis=1)\n","\n","    locales = stores[['gmap_id', 'name', 'address', 'latitude', 'longitude', 'state', 'delivery']]\n","\n","    #Buscar id del estado\n","    sql = \"SELECT * FROM estados\"\n","    cursor.execute(sql)\n","    data = cursor.fetchall()\n","    estados = pd.DataFrame(data)\n","    estados.columns = [\"stateID\", \"state\"]\n","\n","    locales = pd.merge(locales, estados, on='state', how='inner')\n","    locales = locales.drop('state', axis=1)\n","    locales = locales[['gmap_id', 'stateID', 'name', 'address', 'latitude', 'longitude', 'delivery']]\n","\n","    #Insertar en tabla locales\n","    values = [(row['gmap_id'], row['stateID'], row['name'], row['address'], row['latitude'], row['longitude'], row['delivery'], row['stateID'], row['name'], row['address'], row['latitude'], row['longitude'], row['delivery']) for _, row in locales.iterrows()]\n","    insert_query = f\"INSERT INTO locales (storeID, stateID, name, address, latitude, longitude, delivery) VALUES (%s, %s, %s, %s, %s, %s, %s) ON DUPLICATE KEY UPDATE stateID=%s, name=%s, address=%s, latitude=%s, longitude=%s, delivery=%s;\"\n","    cursor.executemany(insert_query, values)\n","    mydb.commit()\n","\n","    print('valores insertados:', values)\n","\n","    mydb.commit()\n","    mydb.close()\n","\n","    return stores\n","\n","\n","\n","@test\n","def test_output(output, *args) -> None:\n","    \"\"\"\n","    Template code for testing the output of the block.\n","    \"\"\"\n","    assert output is not None, 'The output is undefined'\n"],"metadata":{"id":"bsg4n88sgZOX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Tabla_categorias\n","if 'custom' not in globals():\n","    from mage_ai.data_preparation.decorators import custom\n","if 'test' not in globals():\n","    from mage_ai.data_preparation.decorators import test\n","\n","from cassandra.cluster import Cluster\n","from cassandra.query import SimpleStatement, dict_factory\n","\n","cluster = Cluster(['186.87.6.161'], port='9042', protocol_version = 5) #IP del servidor y el puerto estandar de cassandra 9042\n","session = cluster.connect('henry')\n","session.row_factory = dict_factory\n","\n","import pandas as pd\n","\n","import mysql.connector\n","\n","mydb = mysql.connector.connect(\n","  host=\"162.241.60.182\",\n","  user=\"leudadoc_henry\",\n","  password=\"tenboj-dEckow-nokka8\",\n","  database=\"leudadoc_Henry\"\n",")\n","\n","cursor = mydb.cursor()\n","cursor.execute(\"USE leudadoc_Henry;\")\n","\n","\n","@custom\n","def transform_custom(stores, *args, **kwargs):\n","    \"\"\"\n","    Args:\n","        data: The output from the upstream parent block (if applicable)\n","        args: The output from any additional upstream blocks\n","\n","    Returns:\n","        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n","    \"\"\"\n","    # Create a new DataFrame with the unique categories\n","    df_category = pd.DataFrame({'category': stores['category'].str.lower().str.split(\", \").explode().unique()})\n","    import re\n","    pattern = r'(\\w+\\s+)restaurant'\n","    df_category['category'] = df_category['category'].str.replace(pattern, r'\\1', regex=True).str.strip()\n","\n","    cursor.execute(\"SELECT * FROM categorias;\")\n","    resp = cursor.fetchall()\n","\n","    mysql_category = pd.DataFrame(resp, columns = ['categoryID', 'category']) # Tabla con categorías ya cargada en MySQL\n","\n","    no_match = df_category.merge(mysql_category, on='category', how='left', indicator=True)\n","    no_match = no_match[no_match['_merge'] == 'left_only']\n","    no_match = no_match.drop('_merge', axis=1)\n","    new_category = no_match [[\"category\"]]\n","\n","    #Insertar en tabla categorias\n","    values = [(row['category'], ) for _, row in new_category.iterrows()]\n","    insert_query = f\"INSERT INTO categorias (category) VALUES (%s);\"\n","    cursor.executemany(insert_query, values)\n","    mydb.commit()\n","\n","    print('valores insertados:', values)\n","\n","    mydb.commit()\n","    mydb.close()\n","\n","    return stores\n","\n","\n","@test\n","def test_output(output, *args) -> None:\n","    \"\"\"\n","    Template code for testing the output of the block.\n","    \"\"\"\n","    assert output is not None, 'The output is undefined'\n"],"metadata":{"id":"dYK_IwOZYl1P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Tabla_intermedia_categoria_local\n","if 'custom' not in globals():\n","    from mage_ai.data_preparation.decorators import custom\n","if 'test' not in globals():\n","    from mage_ai.data_preparation.decorators import test\n","\n","from cassandra.cluster import Cluster\n","from cassandra.query import SimpleStatement, dict_factory\n","\n","cluster = Cluster(['186.87.6.161'], port='9042', protocol_version = 5) #IP del servidor y el puerto estandar de cassandra 9042\n","session = cluster.connect('henry')\n","session.row_factory = dict_factory\n","\n","import pandas as pd\n","\n","import mysql.connector\n","\n","mydb = mysql.connector.connect(\n","  host=\"162.241.60.182\",\n","  user=\"leudadoc_henry\",\n","  password=\"tenboj-dEckow-nokka8\",\n","  database=\"leudadoc_Henry\"\n",")\n","\n","cursor = mydb.cursor()\n","cursor.execute(\"USE leudadoc_Henry;\")\n","\n","@custom\n","def transform_custom(stores, *args, **kwargs):\n","    \"\"\"\n","    Args:\n","        data: The output from the upstream parent block (if applicable)\n","        args: The output from any additional upstream blocks\n","\n","    Returns:\n","        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n","    \"\"\"\n","    # Create a new DataFrame with the unique categories\n","    df_category_store = stores.assign(category = stores['category'].str.lower().str.split(\", \")).explode('category')\n","    import re\n","    pattern = r'(\\w+\\s+)restaurant'\n","    df_category_store['category'] = df_category_store['category'].str.replace(pattern, r'\\1', regex=True).str.strip()\n","    df_category_store = df_category_store[['gmap_id', 'category']]\n","\n","    cursor.execute(\"SELECT * FROM categorias;\")\n","    resp = cursor.fetchall()\n","\n","    mysql_category = pd.DataFrame(resp, columns = ['categoryID', 'category']) # Tabla con categorías ya cargada en MySQL\n","\n","    df_category_store = df_category_store.merge(mysql_category, how='inner', on='category')\n","    df_category_store = df_category_store[['gmap_id', 'categoryID']]\n","\n","    #Insertar en tabla intermedia categoria_local\n","    values = [(row['categoryID'], row['gmap_id']) for _, row in df_category_store.iterrows()]\n","    insert_query = f\"INSERT INTO categoria_local (categoryID, storeID) VALUES (%s, %s);\"\n","    cursor.executemany(insert_query, values)\n","    mydb.commit()\n","\n","    print('valores insertados:', values)\n","\n","    mydb.commit()\n","    mydb.close()\n","\n","    return stores\n","\n","\n","@test\n","def test_output(output, *args) -> None:\n","    \"\"\"\n","    Template code for testing the output of the block.\n","    \"\"\"\n","    assert output is not None, 'The output is undefined'"],"metadata":{"id":"_f0stLeKYr3O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"YDJej_P0YryP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## reviews_california"],"metadata":{"id":"C91lpsh0gKFZ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"CII-s8dfgHFZ"},"outputs":[],"source":["from cassandra.cluster import Cluster\n","from cassandra.query import SimpleStatement, dict_factory\n","\n","import pandas as pd\n","\n","cluster = Cluster(['186.87.6.161'], port='9042', protocol_version = 5) #IP del servidor y el puerto estandar de cassandra 9042\n","session = cluster.connect('henry')\n","session.row_factory = dict_factory\n","\n","if 'data_loader' not in globals():\n","    from mage_ai.data_preparation.decorators import data_loader\n","if 'test' not in globals():\n","    from mage_ai.data_preparation.decorators import test\n","\n","from mage_ai.data_preparation.variable_manager import set_global_variable\n","\n","@data_loader\n","def load_data(*args, **kwargs):\n","\n","    # Acceder a las variables globales de carga\n","    indice_inicio = kwargs['indice_inicio']\n","    tamaño_particion = kwargs['tamaño_particion'] #5000\n","\n","    # Calcular el índice final\n","    indice_fin = indice_inicio + tamaño_particion\n","\n","    statement = SimpleStatement(\"SELECT * FROM reviews WHERE state = 'California';\", fetch_size = 500)\n","    resp = session.execute(statement, timeout=None)\n","\n","    dictionary = {'gmap_id':[], 'state': [], 'user_id':[], 'name': [], 'time':[], 'rating': [], 'text':[], 'resp': []}\n","\n","    for i, row in enumerate(resp):\n","        # Verificar si el índice actual está dentro del rango de la partición\n","        if indice_inicio <= i < indice_fin:\n","            dictionary['gmap_id'].append(row['gmap_id'])\n","            dictionary['state'].append(row['state'])\n","            dictionary['user_id'].append(row['user_id'])\n","            dictionary['name'].append(row['name'])\n","            dictionary['time'].append(row['time'])\n","            dictionary['rating'].append(row['rating'])\n","            dictionary['text'].append(row['text'])\n","            dictionary['resp'].append(row['resp'])\n","\n","    reviews_california = pd.DataFrame(dictionary)\n","\n","    indice_fin = min(indice_fin, indice_inicio + len(reviews_california))\n","\n","    set_global_variable('prueba_cassandra_to_sql', 'indice_inicio', indice_fin)\n","\n","    return reviews_california\n","\n","@test\n","def test_output(output, *args) -> None:\n","    \"\"\"\n","    Template code for testing the output of the block.\n","    \"\"\"\n","    assert output is not None, 'The output is undefined'\n","\n"]},{"cell_type":"code","source":["if 'transformer' not in globals():\n","    from mage_ai.data_preparation.decorators import transformer\n","if 'test' not in globals():\n","    from mage_ai.data_preparation.decorators import test\n","\n","import pandas as pd\n","\n","@transformer\n","def transform(reviews_california, *args, **kwargs):\n","    \"\"\"\n","    Template code for a transformer block.\n","\n","    Add more parameters to this function if this block has multiple parent blocks.\n","    There should be one parameter for each output variable from each parent block.\n","\n","    Args:\n","        data: The output from the upstream parent block\n","        args: The output from any additional upstream blocks (if applicable)\n","\n","    Returns:\n","        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n","    \"\"\"\n","    #Null\n","    reviews_california = reviews_california.dropna(subset=['text'])\n","\n","    # Time to date\n","    reviews_california['time'] = pd.to_datetime(reviews_california['time'], unit='ms')\n","\n","    return reviews_california\n","\n","@test\n","def test_output(output, *args) -> None:\n","    \"\"\"\n","    Template code for testing the output of the block.\n","    \"\"\"\n","    assert output is not None, 'The output is undefined'"],"metadata":{"id":"pFl6N6x0gKyh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if 'custom' not in globals():\n","    from mage_ai.data_preparation.decorators import custom\n","if 'test' not in globals():\n","    from mage_ai.data_preparation.decorators import test\n","\n","from cassandra.cluster import Cluster\n","from cassandra.query import SimpleStatement, dict_factory\n","\n","cluster = Cluster(['186.87.6.161'], port='9042', protocol_version = 5) #IP del servidor y el puerto estandar de cassandra 9042\n","session = cluster.connect('henry')\n","session.row_factory = dict_factory\n","\n","import pandas as pd\n","\n","import mysql.connector\n","\n","mydb = mysql.connector.connect(\n","  host=\"162.241.60.182\",\n","  user=\"leudadoc_henry\",\n","  password=\"tenboj-dEckow-nokka8\",\n","  database=\"leudadoc_Henry\"\n",")\n","\n","cursor = mydb.cursor()\n","cursor.execute(\"USE leudadoc_Henry;\")\n","\n","@custom\n","def transform_custom(reviews_california, *args, **kwargs):\n","    \"\"\"\n","    Args:\n","        data: The output from the upstream parent block (if applicable)\n","        args: The output from any additional upstream blocks\n","\n","    Returns:\n","        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n","    \"\"\"\n","    reviews_california['time'] = pd.to_datetime(reviews_california['time'], unit='ms')\n","\n","    #Insertar en tabla clientes\n","    insert_query = f\"INSERT INTO clientes (clientID, name) VALUES (%s, %s) ON DUPLICATE KEY UPDATE name=%s\"\n","    values = [(row['user_id'], row['name'], row['name']) for _, row in reviews_california.iterrows()]\n","    cursor.executemany(insert_query, values)\n","    mydb.commit()\n","\n","    #Insertar en tabla reviews\n","    insert_query = f\"INSERT INTO reviews (clientID, storeID, date, rating, text) VALUES (%s, %s, %s, %s, %s)\"\n","    values = [(row['user_id'], row['gmap_id'], row['time'], row['rating'], row['text']) for _, row in reviews_california.iterrows()]\n","    cursor.executemany(insert_query, values)\n","    mydb.commit()\n","\n","    #ETL para tabla comentarios\n","    registros_nuevos = len(reviews_california)\n","    sql = \"SELECT * FROM reviews ORDER BY review_id DESC LIMIT {}\".format(registros_nuevos)\n","    cursor.execute(sql)\n","    data = cursor.fetchall()\n","    reviews = pd.DataFrame(data)\n","\n","    df_review_2 = reviews[['user_id', 'time', 'Review_id']]\n","\n","    reviews_final_2 = reviews_california.dropna(subset=['resp'])\n","    reviews_final_2 = reviews_final_2[reviews_final_2['resp'] != 'None']\n","\n","    reviews_final_2 = reviews_final_2[['user_id', 'resp', 'time']]\n","    merged = reviews_final_2.merge(df_review_2, on=['user_id', 'time'], how='inner')\n","\n","    df_comentarios = merged[['Review_id','resp']]\n","    import ast\n","    # Convertimos la cadena en una lista de diccionarios\n","    df_comentarios['resp'] = df_comentarios['resp'].apply(ast.literal_eval)\n","\n","    df_comentarios['time'] = df_comentarios['resp'].apply(lambda x: x['time'])\n","    df_comentarios['text'] = df_comentarios['resp'].apply(lambda x: x['text'])\n","\n","    df_comentarios = df_comentarios.drop('resp', axis=1)\n","\n","    # Time to date\n","    df_comentarios['time'] = pd.to_datetime(df_comentarios['time'], unit='ms')\n","\n","    #Insertar en tabla comentarios\n","    if (len(df_comentarios)) > 0:\n","        insert_query = f\"INSERT INTO comentarios (reviewID, text, date) VALUES (%s, %s, %s)\"\n","        values = [(row['Review_id'], row['text'], row['date']) for _, row in df_comentarios.iterrows()]\n","        if (len(df_comentarios)) > 1:\n","            cursor.executemany(insert_query, values)\n","            mydb.commit()\n","        elif (len(df_comentarios)) == 1:\n","            cursor.execute(insert_query, values)\n","            mydb.commit()\n","        else: print(\"No hay datos para insertar en comentarios\")\n","    else: print(\"No hay datos para insertar en comentarios\")\n","\n","    cursor.close()\n","    mydb.close()\n","\n","    return reviews_california\n","\n","\n","@test\n","def test_output(output, *args) -> None:\n","    \"\"\"\n","    Template code for testing the output of the block.\n","    \"\"\"\n","    assert output is not None, 'The output is undefined'"],"metadata":{"id":"B2dqjeOqgKwI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6h5V8hjhgKtq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zdBRarWZgKrR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mRpfXESdgKo4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JnHKjnelgKmw"},"execution_count":null,"outputs":[]}]}