{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm -qq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#sns.set()\n",
    "import spacy\n",
    "#import pyLDAvis.gensim_models\n",
    "#pyLDAvis.enable_notebook()# Visualise inside a notebook\n",
    "import en_core_web_sm\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import LdaMulticore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['food', 'atmosphere', 'customer', 'support']\n"
     ]
    }
   ],
   "source": [
    "# Load the spaCy model\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "# Text of a single review\n",
    "review_text = 'The food was ok, the atmosphere clean and luminous, good customer support'\n",
    "\n",
    "\n",
    "# Tags you want to remove from the text\n",
    "removal = ['ADV', 'PRON', 'CCONJ', 'PUNCT', 'PART', 'DET', 'ADP', 'SPACE', 'NUM', 'SYM', 'SCONJ', 'ADP', 'ADJ']\n",
    "\n",
    "# Process the review text using the spaCy model\n",
    "doc = nlp(review_text)\n",
    "\n",
    "# Extract the tokens based on specified conditions\n",
    "tokens = [token.lemma_.lower() for token in doc if token.pos_ not in removal and not token.is_stop and token.is_alpha]\n",
    "\n",
    "# Print the tokens\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.020001547),\n",
       " (1, 0.2360388),\n",
       " (2, 0.020001374),\n",
       " (3, 0.020001374),\n",
       " (4, 0.020004625),\n",
       " (5, 0.020001417),\n",
       " (6, 0.020001376),\n",
       " (7, 0.02000531),\n",
       " (8, 0.020003451),\n",
       " (9, 0.6039407)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and Check the model\n",
    "lda_model_loaded = LdaMulticore.load('./LDA_model/lda_model_10topics')\n",
    "dictionary = Dictionary.load('./GensimDictionary/dictionary.dict')\n",
    "\n",
    "# Test prediction\n",
    "#test_review = 'Amazing staff, they were very friendly and kind answering our questions'\n",
    "#test_tokens = ['Amazing', 'staff', 'friendly', 'kind' , 'question']\n",
    "#test_tokens = ['Afforable', 'quality', 'cheap', 'worthy' ]\n",
    "\n",
    "\n",
    "#test_dictionary = Dictionary(test_tokens.values())\n",
    "new_doc_bow = dictionary.doc2bow(tokens)\n",
    "lda_model_loaded.get_document_topics(new_doc_bow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['staff', 'answer', 'question']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 0.025006069),\n",
       " (1, 0.02501011),\n",
       " (2, 0.02500165),\n",
       " (3, 0.025001584),\n",
       " (4, 0.62480426),\n",
       " (5, 0.025001584),\n",
       " (6, 0.025001584),\n",
       " (7, 0.02500389),\n",
       " (8, 0.02500611),\n",
       " (9, 0.17516315)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import LdaMulticore\n",
    "\n",
    "def get_topics(review_text=''):\n",
    "\n",
    "    # Load the spaCy model\n",
    "    nlp = en_core_web_sm.load()\n",
    "\n",
    "    # Tags you want to remove from the text\n",
    "    removal = ['ADV', 'PRON', 'CCONJ', 'PUNCT', 'PART', 'DET', 'ADP', 'SPACE', 'NUM', 'SYM', 'SCONJ', 'ADP', 'ADJ']\n",
    "\n",
    "    # Process the review text using the spaCy model\n",
    "    doc = nlp(review_text)\n",
    "\n",
    "    # Extract the tokens based on specified conditions\n",
    "    tokens = [token.lemma_.lower() for token in doc if token.pos_ not in removal and not token.is_stop and token.is_alpha]\n",
    "\n",
    "    # Load and Check the model\n",
    "    lda_model_loaded = LdaMulticore.load('./LDA_model/lda_model_10topics')\n",
    "    dictionary = Dictionary.load('./GensimDictionary/dictionary.dict')\n",
    "\n",
    "\n",
    "    # Predict\n",
    "    new_doc_bow = dictionary.doc2bow(tokens)\n",
    "    topics_probabilities = lda_model_loaded.get_document_topics(new_doc_bow)\n",
    "\n",
    "    return topics_probabilities\n",
    "\n",
    "\n",
    "\n",
    "review_text = 'The food was ok, the atmosphere clean and luminous, good customer support'\n",
    "review_text2 ='Amazing staff, they were very friendly and kind answering our questions'\n",
    "\n",
    "get_topics(review_text = review_text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topics meaning:\n",
    "\n",
    "0. Family friendly\n",
    "1. Family owned business - Small Cozy \n",
    "2. Desserts Quality\n",
    "3. Menu variety\n",
    "4. Waiting time (take order, answer questions and bring food)\n",
    "5. Food Quality ( International food)\n",
    "6. Food Quality ( Tasteful and generous)\n",
    "7. Traditional Location (pretty unchaged over time)\n",
    "8. Fun night Atmosphere (Bar - Pub place for night meetings)\n",
    "9. Customer Support, enjoyable atmosphere and Afforable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.3; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Marco\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.26.0-py2.py3-none-any.whl (8.1 MB)\n",
      "     ---------------------------------------- 8.1/8.1 MB 5.6 MB/s eta 0:00:00\n",
      "Collecting rich<14,>=10.14.0\n",
      "  Downloading rich-13.5.2-py3-none-any.whl (239 kB)\n",
      "     -------------------------------------- 239.7/239.7 KB 4.9 MB/s eta 0:00:00\n",
      "Collecting toml<2,>=0.10.1\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting tzlocal<5,>=1.1\n",
      "  Downloading tzlocal-4.3.1-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\marco\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (5.3.1)\n",
      "Collecting watchdog>=2.1.5\n",
      "  Downloading watchdog-3.0.0-py3-none-win_amd64.whl (82 kB)\n",
      "     ---------------------------------------- 82.0/82.0 KB 4.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions<5,>=4.1.0 in c:\\users\\marco\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (4.7.1)\n",
      "Requirement already satisfied: requests<3,>=2.18 in c:\\users\\marco\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (2.27.1)\n",
      "Collecting importlib-metadata<7,>=1.4\n",
      "  Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: pillow<10,>=7.1.0 in c:\\users\\marco\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (9.5.0)\n",
      "Collecting pyarrow>=6.0\n",
      "  Downloading pyarrow-13.0.0-cp310-cp310-win_amd64.whl (24.3 MB)\n",
      "     ---------------------------------------- 24.3/24.3 MB 4.5 MB/s eta 0:00:00\n",
      "Collecting pympler<2,>=0.9\n",
      "  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
      "     -------------------------------------- 164.8/164.8 KB 4.8 MB/s eta 0:00:00\n",
      "Collecting tenacity<9,>=8.1.0\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\marco\\appdata\\roaming\\python\\python310\\site-packages (from streamlit) (6.2)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.3 in c:\\users\\marco\\appdata\\roaming\\python\\python310\\site-packages (from streamlit) (2.8.2)\n",
      "Collecting validators<1,>=0.2\n",
      "  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7\n",
      "  Downloading GitPython-3.1.34-py3-none-any.whl (188 kB)\n",
      "     -------------------------------------- 188.6/188.6 KB 5.8 MB/s eta 0:00:00\n",
      "Collecting pydeck<1,>=0.8\n",
      "  Downloading pydeck-0.8.0-py2.py3-none-any.whl (4.7 MB)\n",
      "     ---------------------------------------- 4.7/4.7 MB 5.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in c:\\users\\marco\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (4.24.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\marco\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (8.0.4)\n",
      "Requirement already satisfied: numpy<2,>=1.19.3 in c:\\users\\marco\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (1.24.3)\n",
      "Collecting blinker<2,>=1.0.0\n",
      "  Downloading blinker-1.6.2-py3-none-any.whl (13 kB)\n",
      "Collecting altair<6,>=4.0\n",
      "  Downloading altair-5.1.1-py3-none-any.whl (520 kB)\n",
      "     -------------------------------------- 520.6/520.6 KB 5.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging<24,>=16.8 in c:\\users\\marco\\appdata\\roaming\\python\\python310\\site-packages (from streamlit) (23.0)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in c:\\users\\marco\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (2.0.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\marco\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.0.3)\n",
      "Collecting toolz\n",
      "  Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\n",
      "     ---------------------------------------- 55.8/55.8 KB 3.0 MB/s eta 0:00:00\n",
      "Collecting jsonschema>=3.0\n",
      "  Downloading jsonschema-4.19.0-py3-none-any.whl (83 kB)\n",
      "     ---------------------------------------- 83.4/83.4 KB 4.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\marco\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "     ---------------------------------------- 62.7/62.7 KB 3.3 MB/s eta 0:00:00\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.16.2-py3-none-any.whl (7.2 kB)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\marco\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\marco\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\marco\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\marco\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.18->streamlit) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\marco\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.18->streamlit) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\marco\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.18->streamlit) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\marco\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.18->streamlit) (1.26.8)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\marco\\appdata\\roaming\\python\\python310\\site-packages (from rich<14,>=10.14.0->streamlit) (2.14.0)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "     ---------------------------------------- 87.5/87.5 KB 4.8 MB/s eta 0:00:00\n",
      "Collecting pytz-deprecation-shim\n",
      "  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\marco\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.0)\n",
      "Collecting rpds-py>=0.7.1\n",
      "  Downloading rpds_py-0.10.2-cp310-none-win_amd64.whl (184 kB)\n",
      "     -------------------------------------- 184.5/184.5 KB 5.6 MB/s eta 0:00:00\n",
      "Collecting referencing>=0.28.4\n",
      "  Downloading referencing-0.30.2-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\marco\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6\n",
      "  Downloading jsonschema_specifications-2023.7.1-py3-none-any.whl (17 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: zipp, watchdog, validators, toolz, toml, tenacity, smmap, rpds-py, pytz-deprecation-shim, pympler, pyarrow, mdurl, blinker, tzlocal, referencing, pydeck, markdown-it-py, importlib-metadata, gitdb, rich, jsonschema-specifications, gitpython, jsonschema, altair, streamlit\n",
      "Successfully installed altair-5.1.1 blinker-1.6.2 gitdb-4.0.10 gitpython-3.1.34 importlib-metadata-6.8.0 jsonschema-4.19.0 jsonschema-specifications-2023.7.1 markdown-it-py-3.0.0 mdurl-0.1.2 pyarrow-13.0.0 pydeck-0.8.0 pympler-1.0.1 pytz-deprecation-shim-0.1.0.post0 referencing-0.30.2 rich-13.5.2 rpds-py-0.10.2 smmap-5.0.0 streamlit-1.26.0 tenacity-8.2.3 toml-0.10.2 toolz-0.12.0 tzlocal-4.3.1 validators-0.22.0 watchdog-3.0.0 zipp-3.16.2\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
